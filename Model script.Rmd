---
title: "Humana Competition Modeling Scripts"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(data.table)
library(readxl)
library(tidyverse)
library(VIM)
library(dplyr)
```


# Data cleaning
ddl: 9.23 12:00pm (give cat variable)

```{r}
data = fread('../2022_Competition_Training.csv')
heading = read_excel('../Humana_Mays_2022_DataDictionary.xlsx', sheet = 'Data Dictionary')
heading = heading %>% janitor::clean_names()
```


## missing data: 
<80% imputation(knn, bagging, numerical mean)
fread()
## quantitive

## categorical
!!!sparse data (in the quantitive as well)

```{r}
## data cleaning
col_cat = heading[which(heading$data_type=='string'),]$feature_name
cat = data[,..col_cat] %>% as.data.frame()
cat[cat=='null'] = NA
cat = cat %>%
  mutate_all(as.factor)

## summary
summary(cat,maxsum = 10)
```

```{r}
## replace missing value with KNN
cat2 = kNN(cat)
# load('knn_cat.Rdata')
cat22 = cat2 %>% dplyr::select(!ends_with('_imp'))
summary(cat22)

### other method in imputation
### 1. Hot deck pmm
library(mice)

start = Sys.time()
cat3 = mice(cat, m = 5, method = "pmm")
cat3_all = complete(cat3, "repeated",include = TRUE)
### get the mode of repeated imputations

cat33 = data.frame(matrix(ncol = 0, nrow = nrow(cat3_all)))
for (col in col_cat){
  subset = cat3_all %>% select(starts_with(col))
  cat33[,col] = apply(subset, 1, function(x){
    if ( is.na(x[1]) ){
      return( names(which.max(table(x[-1]))) ) ## the mode result in repeated pmm
    } else return(x[1])
  })
}

Sys.time() - start

```

* `cat22` is the final dataset after KNN imputation of categorical data
* `cat33` is the final dataset after pmm hot-deck imputation of categorical data

### data manipulation

```{r}
### create metro column, 1 = metro counties, 0 = non-metro counties
cat_metro = cat22 %>% 
  mutate(metro = ifelse(grepl("Metro", rucc_category) , 1, 0))
```

* cat_metro - cat22 dataset with metro column

# Feature Engineering
ddl: 9.24 9:00 pm


# Dataset manipulation (balancing)


# Model Selection -
Tips: scale and regularization before training
## xgboost

## lightGBM

## other models ...

# parameter tuning for models


# Model Evaluation
ddl: 10.1

